{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tqdm gensim keras nltk numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jW4jw3EDC8SR"
   },
   "source": [
    "## Sentiment Analysis on Twitter Data using FastText (gensim) in Keras\n",
    "\n",
    "Sentiment Analysis refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine.[[Source: Wikipedia](https://en.wikipedia.org/wiki/Sentiment_analysis)]\n",
    "\n",
    "I attempt here to perform sentiment analysis using **FastText** Text Embedding from [**gensim**](https://github.com/RaRe-Technologies/gensim).\n",
    "\n",
    "The analysis and training is performed on 400,000 Tweets which are either **Positive** or **Negative**\n",
    "\n",
    "With training on 400,000 Tweets, using fastText, I was able to achieve an accuracy of approximately **69%**\n",
    "\n",
    "### Preprocessing Tweets\n",
    "\n",
    "Dataset is read from .txt file and then shuffled for mainting random distribution.\n",
    "\n",
    "Labels are then generated from each tweet.\n",
    "\n",
    "Finally all of the tweets are tokenized (`RegexpTokenizer()`) and then Lemmatized (`WordNetLemmatizer()`) for only storing the root words. \n",
    "\n",
    "All the variables or lists are deleted to save memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 981127,
     "status": "ok",
     "timestamp": 1532868013545,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102302691480714007423"
     },
     "user_tz": -330
    },
    "id": "LOgOLhHXU9EL",
    "outputId": "c2903a96-8941-4555-9851-2d1d25639ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/400000 [00:00<16:15, 409.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Labels ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [13:56<00:00, 478.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/400000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Lemmatizing ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [02:19<00:00, 2876.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "random.seed(1000)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z0-9]\\w+')\n",
    "\n",
    "pos_tweets = []\n",
    "neg_tweets = []\n",
    "\n",
    "with open('pos_1.2M.txt', 'r', buffering=1000) as f:\n",
    "    pos_tweets = f.readlines()\n",
    "\n",
    "with open('neg_1.2M.txt', 'r', buffering=1000) as f:\n",
    "    neg_tweets = f.readlines()\n",
    "\n",
    "pos_tweets = pos_tweets[:200000]\n",
    "neg_tweets = neg_tweets[:200000]\n",
    "  \n",
    "print('Shuffling ..')\n",
    "tweets_unclean = list(pos_tweets) + list(neg_tweets)\n",
    "random.shuffle(tweets_unclean)\n",
    "\n",
    "print('Generating Labels ..')\n",
    "labels = []\n",
    "\n",
    "with tqdm(total=len(tweets_unclean)) as pbar:\n",
    "    for tweet in tweets_unclean:\n",
    "        if tweet in pos_tweets:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "              labels.append(0)\n",
    "\n",
    "        pbar.update(1)\n",
    "    \n",
    "del pos_tweets\n",
    "del neg_tweets\n",
    "\n",
    "print('Tokenizing ..')\n",
    "tweets = [tokenizer.tokenize(tweet.lower()) for tweet in tweets_unclean]\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "tweets = []\n",
    "\n",
    "print('Lemmatizing ..')\n",
    "\n",
    "with tqdm(total=len(tweets_unclean)) as pbar:\n",
    "    for tweet in tweets_unclean:\n",
    "        lemmatized = [lemmatizer.lemmatize(word) for word in tweet]\n",
    "        tweets.append(lemmatized)\n",
    "        pbar.update(1)\n",
    "\n",
    "del tweets_unclean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7eC6qc7DNyu"
   },
   "source": [
    "### Generating FastText and storing the Model\n",
    "fastText is a library for learning of word embeddings and text classification created by Facebook's AI Research (FAIR) lab. The model is an unsupervised learning algorithm for obtaining vector representations for words. Facebook makes available pretrained models for 294 languages. fastText uses Neural network for word embedding\n",
    " [[Source: Wikipedia](https://en.wikipedia.org/wiki/FastText)]\n",
    "\n",
    "Docs on Gensim: [models.fasttext](https://radimrehurek.com/gensim/models/fasttext.html)\n",
    "\n",
    "FastText is an extension to Word2Vec proposed by Facebook in 2016. Instead of feeding individual words into the Neural Network, FastText breaks words into several n-grams (sub-words). For instance, the tri-grams for the word apple is app, ppl, and ple (ignoring the starting and ending of boundaries of words). The word embedding vector for apple will be the sum of all these n-grams. After training the Neural Network, we will have word embeddings for all the n-grams given the training dataset. Rare words can now be properly represented since it is highly likely that some of their n-grams also appears in other words. I will show you how to use FastText with Gensim in the following section.\n",
    "\n",
    "![FastText Example](fasttext-example.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2w0wWGDhdeHh"
   },
   "outputs": [],
   "source": [
    "vector_size = 256\n",
    "window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141264,
     "status": "ok",
     "timestamp": 1532868156185,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102302691480714007423"
     },
     "user_tz": -330
    },
    "id": "waUN7DMLWW_K",
    "outputId": "2f8a7189-8790-406e-926d-8957f78ad1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating FastText Vectors ..\n",
      "FastText Created in 138.93589448928833 seconds.\n",
      "FastText Model saved at fasttext.model\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "import time\n",
    "\n",
    "fasttext_model = 'fasttext.model'\n",
    "\n",
    "print('Generating FastText Vectors ..')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = FastText(size=vector_size)\n",
    "model.build_vocab(tweets)\n",
    "model.train(tweets, window=window, min_count=1, workers=4, total_examples=model.corpus_count,\n",
    "           epochs=model.epochs)\n",
    "\n",
    "print('FastText Created in {} seconds.'.format(time.time() - start))\n",
    "\n",
    "model.save(fasttext_model)\n",
    "print('FastText Model saved at {}'.format(fasttext_model))\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7aYHPnlKk7gy"
   },
   "outputs": [],
   "source": [
    "model = FastText.load(fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mwXQ37rJsTzo"
   },
   "outputs": [],
   "source": [
    "x_vectors = model.wv\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1532868161582,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102302691480714007423"
     },
     "user_tz": -330
    },
    "id": "hmy7ziZrsXGx",
    "outputId": "8fa59b8e-188b-429b-e21f-a282e6f9f2ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 400000)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels), len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9x7HSbVhEJh6"
   },
   "source": [
    "### Dataset Partition\n",
    "\n",
    "Spliting the tweets and labels in `(x_train, y_train)` and `(x_test, y_test)` with 90% for training and 10% for testing from all the tweets.\n",
    "\n",
    "Maximum number of tokens allowed for each tweet is set to be 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13456,
     "status": "ok",
     "timestamp": 1532868175143,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102302691480714007423"
     },
     "user_tz": -330
    },
    "id": "OPZ1DhxNueMQ",
    "outputId": "99f50dd7-0185-4e26-d61e-d1420630b72e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "train_size = int(0.9*(len(tweets)))\n",
    "test_size = int(0.1*(len(tweets)))\n",
    "\n",
    "max_no_tokens = 15\n",
    "\n",
    "indexes = set(np.random.choice(len(tweets), train_size + test_size, replace=False))\n",
    "\n",
    "x_train = np.zeros((train_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
    "y_train = np.zeros((train_size, 2), dtype=np.int32)\n",
    "\n",
    "x_test = np.zeros((test_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
    "y_test = np.zeros((test_size, 2), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ADEodjHivhGe"
   },
   "outputs": [],
   "source": [
    "for i, index in enumerate(indexes):\n",
    "    for t, token in enumerate(tweets[index]):\n",
    "        if t >= max_no_tokens:\n",
    "            break\n",
    "      \n",
    "        if token not in x_vectors:\n",
    "            continue\n",
    "    \n",
    "        if i < train_size:\n",
    "            x_train[i, t, :] = x_vectors[token]\n",
    "        else:\n",
    "            x_test[i - train_size, t, :] = x_vectors[token]\n",
    "\n",
    "  \n",
    "    if i < train_size:\n",
    "        y_train[i, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
    "    else:\n",
    "        y_test[i - train_size, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
    "    \n",
    "del tweets\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1532868204135,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102302691480714007423"
     },
     "user_tz": -330
    },
    "id": "ntJKWYdRxURp",
    "outputId": "ae0ccada-c01a-4110-91bd-cfc9f2360572"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360000, 15, 256), (40000, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KtiWWSSEP8Z"
   },
   "source": [
    "### Building the Neural Model\n",
    "\n",
    "For training a combination of Convolution Neural Network and Bidirectional Long Short Term Memory Network is used (CNN-LSTM).\n",
    "\n",
    "Batch Size is 100.\n",
    "\n",
    "\n",
    "To prevent overfitting or over training of the network, `EarlyStopping()` is used in `callbacks` thus if the network does not improve or starts overfitting, the training comes to an end.\n",
    "\n",
    "**Acrhitecture of Network:**\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "Conv1D -> Conv1D -> Conv1D -> Max Pooling1D -> Bidirectional LSTM -> Dense -> Dropout -> Dense -> Dropout -> Dense -> Dropout -> Output\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "Total params: 3,314,274\n",
    "\n",
    "Trainable params: 3,314,274\n",
    "\n",
    "Non-trainable params: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hCLQdrPoC9X8"
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "no_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11326,
     "status": "ok",
     "timestamp": 1532868217906,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102302691480714007423"
     },
     "user_tz": -330
    },
    "id": "_wiKyELIxrsa",
    "outputId": "d3e5f954-8626-4d8d-ee52-bdf6ab6f03be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 15, 32)            24608     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 15, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 15, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5, 32)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1024)              2232320   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,314,274\n",
      "Trainable params: 3,314,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same',\n",
    "                 input_shape=(max_no_tokens, vector_size)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "\n",
    "model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-QiTfk4Em-z"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1278
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1989940,
     "status": "ok",
     "timestamp": 1532870207887,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102302691480714007423"
     },
     "user_tz": -330
    },
    "id": "IPfQ-P0y3znW",
    "outputId": "22c18626-db75-4279-ed46-f375066ea05e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 360000 samples, validate on 40000 samples\n",
      "Epoch 1/100\n",
      "153000/360000 [===========>..................] - ETA: 34s - loss: 0.7053 - acc: 0.5431360000/360000 [==============================] - 59s 165us/step - loss: 0.6774 - acc: 0.5853 - val_loss: 0.6326 - val_acc: 0.6410\n",
      "Epoch 2/100\n",
      "141000/360000 [==========>...................] - ETA: 33s - loss: 0.6410 - acc: 0.6314360000/360000 [==============================] - 57s 158us/step - loss: 0.6341 - acc: 0.6376 - val_loss: 0.6160 - val_acc: 0.6560\n",
      "Epoch 3/100\n",
      "136500/360000 [==========>...................] - ETA: 33s - loss: 0.6242 - acc: 0.6440360000/360000 [==============================] - 57s 157us/step - loss: 0.6206 - acc: 0.6484 - val_loss: 0.6053 - val_acc: 0.6622\n",
      "Epoch 4/100\n",
      "134500/360000 [==========>...................] - ETA: 34s - loss: 0.6126 - acc: 0.6563360000/360000 [==============================] - 57s 157us/step - loss: 0.6115 - acc: 0.6570 - val_loss: 0.6009 - val_acc: 0.6657\n",
      "Epoch 5/100\n",
      "134000/360000 [==========>...................] - ETA: 34s - loss: 0.6066 - acc: 0.6611360000/360000 [==============================] - 57s 157us/step - loss: 0.6056 - acc: 0.6612 - val_loss: 0.5953 - val_acc: 0.6693\n",
      "Epoch 6/100\n",
      "134000/360000 [==========>...................] - ETA: 34s - loss: 0.6026 - acc: 0.6663360000/360000 [==============================] - 57s 157us/step - loss: 0.6013 - acc: 0.6664 - val_loss: 0.5926 - val_acc: 0.6737\n",
      "Epoch 7/100\n",
      "134000/360000 [==========>...................] - ETA: 34s - loss: 0.5970 - acc: 0.6692360000/360000 [==============================] - 57s 157us/step - loss: 0.5975 - acc: 0.6693 - val_loss: 0.5896 - val_acc: 0.6739\n",
      "Epoch 8/100\n",
      "134000/360000 [==========>...................] - ETA: 34s - loss: 0.5959 - acc: 0.6722360000/360000 [==============================] - 57s 157us/step - loss: 0.5946 - acc: 0.6722 - val_loss: 0.5874 - val_acc: 0.6766\n",
      "Epoch 9/100\n",
      "134000/360000 [==========>...................] - ETA: 34s - loss: 0.5919 - acc: 0.6749360000/360000 [==============================] - 57s 157us/step - loss: 0.5920 - acc: 0.6741 - val_loss: 0.5889 - val_acc: 0.6765\n",
      "Epoch 10/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5888 - acc: 0.6762360000/360000 [==============================] - 56s 156us/step - loss: 0.5899 - acc: 0.6755 - val_loss: 0.5840 - val_acc: 0.6796\n",
      "Epoch 11/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5874 - acc: 0.6780360000/360000 [==============================] - 56s 156us/step - loss: 0.5876 - acc: 0.6772 - val_loss: 0.5823 - val_acc: 0.6815\n",
      "Epoch 12/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5864 - acc: 0.6784360000/360000 [==============================] - 56s 157us/step - loss: 0.5857 - acc: 0.6793 - val_loss: 0.5804 - val_acc: 0.6830\n",
      "Epoch 13/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5839 - acc: 0.6811360000/360000 [==============================] - 57s 157us/step - loss: 0.5844 - acc: 0.6798 - val_loss: 0.5800 - val_acc: 0.6843\n",
      "Epoch 14/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5819 - acc: 0.6823360000/360000 [==============================] - 57s 157us/step - loss: 0.5825 - acc: 0.6818 - val_loss: 0.5808 - val_acc: 0.6833\n",
      "Epoch 15/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5801 - acc: 0.6838360000/360000 [==============================] - 57s 157us/step - loss: 0.5815 - acc: 0.6824 - val_loss: 0.5812 - val_acc: 0.6817\n",
      "Epoch 16/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5810 - acc: 0.6830360000/360000 [==============================] - 56s 157us/step - loss: 0.5803 - acc: 0.6839 - val_loss: 0.5768 - val_acc: 0.6835\n",
      "Epoch 17/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5784 - acc: 0.6849360000/360000 [==============================] - 57s 158us/step - loss: 0.5788 - acc: 0.6841 - val_loss: 0.5762 - val_acc: 0.6864\n",
      "Epoch 18/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5760 - acc: 0.6864360000/360000 [==============================] - 57s 157us/step - loss: 0.5770 - acc: 0.6862 - val_loss: 0.5774 - val_acc: 0.6859\n",
      "Epoch 19/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5761 - acc: 0.6868360000/360000 [==============================] - 57s 157us/step - loss: 0.5763 - acc: 0.6871 - val_loss: 0.5780 - val_acc: 0.6826\n",
      "Epoch 20/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5753 - acc: 0.6867360000/360000 [==============================] - 57s 157us/step - loss: 0.5753 - acc: 0.6876 - val_loss: 0.5739 - val_acc: 0.6871\n",
      "Epoch 21/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5740 - acc: 0.6872360000/360000 [==============================] - 56s 157us/step - loss: 0.5747 - acc: 0.6881 - val_loss: 0.5750 - val_acc: 0.6861\n",
      "Epoch 22/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5733 - acc: 0.6888360000/360000 [==============================] - 56s 157us/step - loss: 0.5735 - acc: 0.6888 - val_loss: 0.5718 - val_acc: 0.6899\n",
      "Epoch 23/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5714 - acc: 0.6897360000/360000 [==============================] - 57s 157us/step - loss: 0.5728 - acc: 0.6898 - val_loss: 0.5717 - val_acc: 0.6900\n",
      "Epoch 24/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5719 - acc: 0.6888360000/360000 [==============================] - 57s 158us/step - loss: 0.5719 - acc: 0.6900 - val_loss: 0.5720 - val_acc: 0.6906\n",
      "Epoch 25/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5705 - acc: 0.6919360000/360000 [==============================] - 57s 157us/step - loss: 0.5714 - acc: 0.6902 - val_loss: 0.5704 - val_acc: 0.6917\n",
      "Epoch 26/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5714 - acc: 0.6904360000/360000 [==============================] - 57s 157us/step - loss: 0.5707 - acc: 0.6916 - val_loss: 0.5706 - val_acc: 0.6923\n",
      "Epoch 27/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5698 - acc: 0.6935360000/360000 [==============================] - 57s 157us/step - loss: 0.5697 - acc: 0.6924 - val_loss: 0.5756 - val_acc: 0.6885\n",
      "Epoch 28/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5673 - acc: 0.6942360000/360000 [==============================] - 57s 157us/step - loss: 0.5687 - acc: 0.6934 - val_loss: 0.5697 - val_acc: 0.6917\n",
      "Epoch 29/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5668 - acc: 0.6957360000/360000 [==============================] - 57s 157us/step - loss: 0.5680 - acc: 0.6945 - val_loss: 0.5703 - val_acc: 0.6910\n",
      "Epoch 30/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5658 - acc: 0.6947360000/360000 [==============================] - 57s 157us/step - loss: 0.5675 - acc: 0.6939 - val_loss: 0.5676 - val_acc: 0.6942\n",
      "Epoch 31/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5660 - acc: 0.6947360000/360000 [==============================] - 57s 157us/step - loss: 0.5669 - acc: 0.6948 - val_loss: 0.5683 - val_acc: 0.6937\n",
      "Epoch 32/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5660 - acc: 0.6951360000/360000 [==============================] - 56s 157us/step - loss: 0.5667 - acc: 0.6947 - val_loss: 0.5668 - val_acc: 0.6959\n",
      "Epoch 33/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5654 - acc: 0.6950360000/360000 [==============================] - 56s 157us/step - loss: 0.5657 - acc: 0.6957 - val_loss: 0.5689 - val_acc: 0.6910\n",
      "Epoch 34/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5649 - acc: 0.6968360000/360000 [==============================] - 56s 157us/step - loss: 0.5657 - acc: 0.6954 - val_loss: 0.5672 - val_acc: 0.6953\n",
      "Epoch 35/100\n",
      "133000/360000 [==========>...................] - ETA: 34s - loss: 0.5625 - acc: 0.6987360000/360000 [==============================] - 57s 158us/step - loss: 0.5645 - acc: 0.6958 - val_loss: 0.5669 - val_acc: 0.6959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2529da1710>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=no_epochs,\n",
    "         validation_data=(x_test, y_test), callbacks=[tensorboard, EarlyStopping(min_delta=0.0001, patience=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TowrJ3QGEqax"
   },
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1532870209142,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102302691480714007423"
     },
     "user_tz": -330
    },
    "id": "tQmcfrwu5pak",
    "outputId": "a8a72b47-dd86-4fd0-9a0e-7cc7caba2bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16067,
     "status": "ok",
     "timestamp": 1532870226197,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102302691480714007423"
     },
     "user_tz": -330
    },
    "id": "9hAXHL915SPX",
    "outputId": "376b2cee-3b85-44a4-97c5-26db22d8b8e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 15s 376us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5668948031425476, 0.69585]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPQ4ofRjE0Gk"
   },
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FDgLrrbu7uAX"
   },
   "outputs": [],
   "source": [
    "model.save('twitter-sentiment-fasttext.model')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "sentiment_analysis_fastext.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
