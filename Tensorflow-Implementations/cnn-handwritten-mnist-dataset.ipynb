{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTRjQlEjKAzK"
   },
   "source": [
    "By: Jatin Kumar Mandav\n",
    "\n",
    "Module: TensorFlow\n",
    "\n",
    "Website: [Mandav's Blog](https://jatinmandav.wordpress.com)\n",
    "\n",
    "YouTube Channel: [Mandav](https://youtube.com/mandav)\n",
    "\n",
    "Twitter: [@jatinmandav](https://twitter.com/jatinmandav)\n",
    "\n",
    "\n",
    "# **Building Convolutional Neural Network Using [Tensorflow](https://www.tensorflow.org/)**\n",
    "\n",
    "\n",
    "Let's Build a simple CNN for Handwritten numbers from MNIST Dataset (<http://yann.lecun.com/exdb/mnist/>)\n",
    "\n",
    "CNN Architecture that I wil be Building is following:\n",
    "  - Convolution Layer 1: 5x5 Kernel\n",
    "  - Max - pool Layer: 2x2 Kernel\n",
    "  - Convolution Layer 2: 5x5 Kernel\n",
    "  - Convolution Layer 3: 5x5 Kernel\n",
    "  - Convolution Layer 4: 5x5 Kernel\n",
    "  - Max - pool Layer: 2x2 Kernel\n",
    "  - Convolution Layer 5: 5x5 Kernel\n",
    "  - Convolution Layer 6: 5x5 Kernel\n",
    "  - Fully Connected Layer with 1024 Neurons\n",
    "  - Output Layer with 10 Neurons\n",
    "  \n",
    "  \n",
    "## **CNN Layout**\n",
    "\n",
    "> ***Conv1*** --> ***ReLU*** --> ***MaxPool*** --> ***Conv1*** --> ***ReLU*** --> ***Conv1*** --> ***ReLU*** --> ***Conv1*** --> ***ReLU*** --> ***MaxPool*** --> ***Conv1*** --> ***ReLU*** --> ***Conv1*** --> ***ReLU*** --> ***FullyConnected*** --> ***ReLU*** ---> ***OutputLayer***\n",
    "\n",
    "\n",
    "\n",
    "**Optimizer:** Adam Optimizer\n",
    "\n",
    "**Activation Function:** ReLU\n",
    "\n",
    "**Cost Function:** Softmax - Cross Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yv8hF0mcJ_ZY"
   },
   "outputs": [],
   "source": [
    "# Imports!\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)\n",
    "\n",
    "no_prediction_classes = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UVbRy-PLKICS"
   },
   "outputs": [],
   "source": [
    "# Place Holders for input image (x) and prediction or correct identification (y)\n",
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "# Drop - Out Place Holder\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mn-CxmCmKKay"
   },
   "source": [
    "**Defining functions for processing using TensorFlow Library!**\n",
    "\n",
    "  -- tf.nn.**conv2d**(input, filter, strides, padding, use_sudnn_on_gpu=True, data_format='NHWC', dilations=[1, 1, 1, 1], name=None)\n",
    "  \n",
    "  -- tf.nn.**max_pool**(value, ksize, strides, padding, data_format='NHWC', name=None)\n",
    "  \n",
    "  -- tf.nn.**relu**(features, name=None)\n",
    "  \n",
    "  -- tf.nn.**dropout**(x, keep_prob, noise_shape=None, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "S920mXszKNjG"
   },
   "outputs": [],
   "source": [
    "# 2D Convolution Function\n",
    "def conv2d(x, filters):\n",
    "  return tf.nn.conv2d(x, filters, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# 2D Max - Pool Function\n",
    "def max_pool2d(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Activation Function\n",
    "def relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# Drop out Function\n",
    "def dropout(x, keep_rate):\n",
    "  return tf.nn.dropout(x, keep_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4gRK8BoKTrw"
   },
   "source": [
    "**MNIST** Dataset is of the form of **1x785** array (or list), which needs to be converted into **28x28x1** 2D Image to pass through a CNN.\n",
    "\n",
    "### **Calculating the Padding**\n",
    "\n",
    "\n",
    "If Padding is ***SAME***:\n",
    "\n",
    "    out_height = ceil(float(in_height)/float(stride[1]))\n",
    "    out_width = ceil(float(in_width)/float(stride[2]))\n",
    "    if in_height % stride[1] == 0:\n",
    "        pad_along_height = max(filter_height - stride[1], 0)\n",
    "    else:\n",
    "        pad_along_height = max(filter_height - (in_height % stride[1]), 0)\n",
    "    if in_width % stride[2] == 0:\n",
    "        pad_along_width = max(filter_width - stride[2], 0)\n",
    "    else:\n",
    "        pad_along_width = max(filter_width - (in_width % stride[2]), 0)\n",
    "        padding_top = pad_along_height // 2\n",
    "        padding_bottom = pad__along_height - padding_top\n",
    "        padding_left = pad_along_width // 2\n",
    "        padding_right = pad__along_width - padding_left    \n",
    "\n",
    "If Padding is ***VALID***:\n",
    "\n",
    "    out_height = ceil(float(in_height - filter_height + 1)/float(stride[1]))\n",
    "    out_width = ceil(float(in_width - filter_width + 1)/float(stride[2]))\n",
    "    No Padding.\n",
    "    \n",
    "\n",
    "  -- Input Tensor Format: [Batch, Height, Width, Channels]\n",
    "\n",
    "  -- Kernel or Filter Format: [Height, Width, In_Channels, Out_Channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DgKreutiKW5q"
   },
   "outputs": [],
   "source": [
    "# Building the Convolutional Neural Network\n",
    "def convolutional_neural_network(x):\n",
    "  # Reshaping MNIST Dataset\n",
    "  x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "  \n",
    "  # Input Size for Layer 1 = [1, 28, 28, 1]\n",
    "  weights_conv1 = tf.Variable(tf.random_normal([5, 5, 1, 32]))\n",
    "  biases_conv1 = tf.Variable(tf.random_normal([32]))\n",
    "  \n",
    "  conv1 = relu(conv2d(x, weights_conv1) + biases_conv1)\n",
    "  \n",
    "  # Max - Pool 1\n",
    "  conv1 = max_pool2d(conv1)\n",
    "  \n",
    "  # Input Size for Layer 2 = [1, 14, 14, 32]\n",
    "  weights_conv2 = tf.Variable(tf.random_normal([5, 5, 32, 32]))\n",
    "  biases_conv2 = tf.Variable(tf.random_normal([32]))\n",
    "  \n",
    "  conv2 = relu(conv2d(conv1, weights_conv2) + biases_conv2)\n",
    "  \n",
    "  # Input Size for Layer 3 = [1, 14, 14, 32]\n",
    "  weights_conv3 = tf.Variable(tf.random_normal([5, 5, 32, 32]))\n",
    "  biases_conv3 = tf.Variable(tf.random_normal([32]))\n",
    "  \n",
    "  conv3 = relu(conv2d(conv2, weights_conv3) + biases_conv3)\n",
    "  \n",
    "  # Input Size for Layer 4 = [1, 14, 14, 32]\n",
    "  weights_conv4 = tf.Variable(tf.random_normal([5, 5, 32, 64]))\n",
    "  biases_conv4 = tf.Variable(tf.random_normal([64]))\n",
    "  \n",
    "  conv4 = relu(conv2d(conv3, weights_conv4) + biases_conv4)\n",
    "  \n",
    "  # Max - Pool 2\n",
    "  conv4 = max_pool2d(conv4)\n",
    "  \n",
    "  # Input Size for Layer 5 = [1, 7, 7, 64]\n",
    "  weights_conv5 = tf.Variable(tf.random_normal([5, 5, 64, 64]))\n",
    "  biases_conv5 = tf.Variable(tf.random_normal([64]))\n",
    "  \n",
    "  conv5 = relu(conv2d(conv4, weights_conv5) + biases_conv5)\n",
    "  \n",
    "  # Input Size for Layer 6 = [1, 7, 7, 64]\n",
    "  weights_conv6 = tf.Variable(tf.random_normal([5, 5, 64, 64]))\n",
    "  biases_conv6 = tf.Variable(tf.random_normal([64]))\n",
    "  \n",
    "  conv6 = relu(conv2d(conv5, weights_conv6) + biases_conv6)\n",
    "  \n",
    "  # Input Size for Fully Connected Layer = 7*7*64\n",
    "  weights_fc = tf.Variable(tf.random_normal([7*7*64, 1024]))\n",
    "  biases_fc = tf.Variable(tf.random_normal([1024]))\n",
    "  \n",
    "  # Flattening Conv6 Layer\n",
    "  conv6 = tf.reshape(conv6, shape=[-1, 7*7*64])\n",
    "  \n",
    "  fc = relu(tf.matmul(conv6, weights_fc) + biases_fc)\n",
    "  \n",
    "  # Drop - Out Some Neurons!\n",
    "  keep_rate = 0.8\n",
    "  \n",
    "  fc = dropout(fc, keep_rate)\n",
    "  \n",
    "  # Input Size for Output Layer = [1024]\n",
    "  weights_out = tf.Variable(tf.random_normal([1024, no_prediction_classes]))\n",
    "  biases_out = tf.Variable(tf.random_normal([no_prediction_classes]))\n",
    "  \n",
    "  out_layer = tf.matmul(fc, weights_out) + biases_out\n",
    "  \n",
    "  # Returning the Output Prediction by out little CNN!\n",
    "  return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SdonkpNKKY0K"
   },
   "source": [
    "## Training!\n",
    "\n",
    "  - **Cost Function:** tf.nn.softmax_cross_entropy_with_logits_v2(_sentinel=None, labels=None, logits=None, dim=-1, name=None)\n",
    "\n",
    "  - **Optimizer:** tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DAafGvUhKbj0"
   },
   "outputs": [],
   "source": [
    "# Training Function!\n",
    "def train_cnn(x):\n",
    "  # Prediction by CNN\n",
    "  prediction = convolutional_neural_network(x)\n",
    "  \n",
    "  # Cost Function\n",
    "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=y))\n",
    "  \n",
    "  # Optimizer\n",
    "  optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "  \n",
    "  total_epochs = 20\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(total_epochs):\n",
    "      epoch_loss = 0\n",
    "      for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "        epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "        \n",
    "        epoch_loss += c\n",
    "        \n",
    "      print('Epoch: ', epoch, ', Loss: ', epoch_loss)\n",
    "      \n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    \n",
    "    for _ in range(10):\n",
    "      test_x, test_y = mnist.test.next_batch(50)\n",
    "      print('Test Accuracy: ', accuracy.eval({x: test_x, y: test_y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Hw4Zia_KfM-"
   },
   "source": [
    "## **Let's Train Our Little Convolutional Neural Network!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 236354,
     "status": "ok",
     "timestamp": 1525726315194,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "nP9-G3CxQAaG",
    "outputId": "dc08653a-484c-4d1a-ad28-49b013d2b65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 , Loss:  368335601432.0\n",
      "Epoch:  1 , Loss:  40375449402.0\n",
      "Epoch:  2 , Loss:  20674348955.5\n",
      "Epoch:  3 , Loss:  13149341593.5\n",
      "Epoch:  4 , Loss:  8713899957.0\n",
      "Epoch:  5 , Loss:  6179719856.0\n",
      "Epoch:  6 , Loss:  4568565831.75\n",
      "Epoch:  7 , Loss:  3340161073.0\n",
      "Epoch:  8 , Loss:  2672170015.625\n",
      "Epoch:  9 , Loss:  2024914225.25\n",
      "Epoch:  10 , Loss:  1786815568.375\n",
      "Epoch:  11 , Loss:  1402784430.0\n",
      "Epoch:  12 , Loss:  1376887850.75\n",
      "Epoch:  13 , Loss:  1216710528.875\n",
      "Epoch:  14 , Loss:  1122335389.75\n",
      "Epoch:  15 , Loss:  869207884.25\n",
      "Epoch:  16 , Loss:  998913421.0\n",
      "Epoch:  17 , Loss:  890400845.5\n",
      "Epoch:  18 , Loss:  761744137.875\n",
      "Epoch:  19 , Loss:  651787629.875\n",
      "Test Accuracy:  0.98\n",
      "Test Accuracy:  1.0\n",
      "Test Accuracy:  0.96\n",
      "Test Accuracy:  0.92\n",
      "Test Accuracy:  1.0\n",
      "Test Accuracy:  0.98\n",
      "Test Accuracy:  0.96\n",
      "Test Accuracy:  0.98\n",
      "Test Accuracy:  0.98\n",
      "Test Accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  train_cnn(x)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
