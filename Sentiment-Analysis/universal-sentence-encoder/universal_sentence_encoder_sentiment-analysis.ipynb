{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_r27VO-P5Ih6"
   },
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow-hub tensorflow numpy pickle tqdm keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaDJkRjCvvCk"
   },
   "source": [
    "## Sentiment Analysis on Twitter Data using Universal Sentence Encoder (TensorFlow) in Keras\n",
    "\n",
    "Sentiment Analysis refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine.[[Source: Wikipedia](https://en.wikipedia.org/wiki/Sentiment_analysis)]\n",
    "\n",
    "I attempt here to perform sentiment analysis using **Universal Sentence Encoder** Text Embedding from [**TensorFlow**](https://www.tensorflow.org/hub/modules/google/universal-sentence-encoder/1).\n",
    "\n",
    "The analysis and training is performed on 400,000 Tweets which are either **Positive** or **Negative**\n",
    "\n",
    "With training on 400,000 Tweets, using Universal Sentence Encoder, I was able to achieve an accuracy of approximately **77%**\n",
    "\n",
    "### Preprocessing Tweets\n",
    "\n",
    "Dataset is read from .txt file and then shuffled for mainting random distribution.\n",
    "\n",
    "Labels are then generated from each tweet.\n",
    "\n",
    "\n",
    "All the variables or lists are deleted to save memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1521210,
     "status": "ok",
     "timestamp": 1532881730625,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "Y4UZMjG3OccZ",
    "outputId": "344ab087-1085-45ff-d135-56f077bc3fea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shuffling ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/400000 [00:00<28:45, 231.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Labels ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [25:19<00:00, 263.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "pos_tweets = []\n",
    "neg_tweets = []\n",
    "\n",
    "with open('pos_1.2M.txt', 'r', buffering=1000) as f:\n",
    "  ptweets = f.readlines()\n",
    "\n",
    "with open('neg_1.2M.txt', 'r', buffering=1000) as f:\n",
    "  ntweets = f.readlines()\n",
    "\n",
    "pos_tweets = ptweets[:200000]\n",
    "neg_tweets = ntweets[:200000]\n",
    "\n",
    "print('\\nShuffling ..')\n",
    "tweets_unclean = list(pos_tweets) + list(neg_tweets)\n",
    "random.shuffle(tweets_unclean)\n",
    "\n",
    "print('\\nGenerating Labels ..')\n",
    "with tqdm(total=len(tweets_unclean)) as pbar:\n",
    "  labels = []\n",
    "  for tweet in tweets_unclean:\n",
    "    if tweet in pos_tweets:\n",
    "      labels.append(1)\n",
    "    else:\n",
    "      labels.append(0)\n",
    "    \n",
    "    pbar.update(1)\n",
    "  \n",
    "del pos_tweets\n",
    "del neg_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kAtpIvyDO3AG"
   },
   "outputs": [],
   "source": [
    "tweets = tweets_unclean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmv9RRVh0ihE"
   },
   "source": [
    "### Generating Embedding\n",
    "\n",
    "Released in 2018, The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.\n",
    "\n",
    "The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a **512 dimensional vector**. We apply this model to the STS benchmark for semantic similarity, and the results can be seen in the example notebook made available. The universal-sentence-encoder model is trained with a deep averaging network (DAN) encoder.\n",
    "\n",
    "Source: [TensorFlow/Hub/Universal-Sentence-Encoder](https://www.tensorflow.org/hub/modules/google/universal-sentence-encoder/2)\n",
    "\n",
    "Embedding are created from the collected 400,000 Tweets using the pretrained model and reshaped to make them ready to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800451,
     "status": "ok",
     "timestamp": 1532882532533,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "Y4oEpkePOKs6",
    "outputId": "5b1626b6-ce0a-406a-c16b-a8cea008ef4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/2'.\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/2'.\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_0:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_0\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_1:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_1\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_10:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_10\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_11:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_11\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_12:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_12\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_13:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_13\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_14:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_14\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_15:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_15\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_16:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_16\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_2:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_2\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_3:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_3\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_4:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_4\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_5:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_5\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_6:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_6\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_7:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_7\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_8:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_8\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_9:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_9\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_0/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_1/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_1/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_2/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_2/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/projection:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_3/projection\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_3/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/LinearLayer/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/LinearLayer/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/global_step:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with global_step\n"
     ]
    }
   ],
   "source": [
    "embed = hub.Module(module_name)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  tweet_embeddings = sess.run(embed(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1773,
     "status": "ok",
     "timestamp": 1532882534334,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "u2cNGZSLPMzT",
    "outputId": "1dbd5122-e6d5-46a3-a2bf-b9e013ea83b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_embeddings = np.array(tweet_embeddings)\n",
    "tweet_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3ZXnYcG_PNzb"
   },
   "outputs": [],
   "source": [
    "tweet_embeddings = np.array([np.reshape(embed, (len(embed), 1)) for embed in tweet_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1532882538445,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "Ot7MeJJ0Qcl7",
    "outputId": "1150c35b-e110-48f1-93b9-ddaf5a75f27b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 512, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGwzgkLZ1gps"
   },
   "source": [
    "### One hot Labels\n",
    "\n",
    "One-hot labels for the tweet dataset are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2421,
     "status": "ok",
     "timestamp": 1532882541211,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "XvvS2JEAKgXg",
    "outputId": "05c5cfd7-a9a8-403f-ac95-1d0d7405e544"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:01<00:00, 345964.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "labels_one_hot = []\n",
    "\n",
    "with tqdm(total=len(labels)) as pbar:\n",
    "  for label in labels:\n",
    "    if label == 0:\n",
    "      labels_one_hot.append([1., 0.])\n",
    "    else:\n",
    "      labels_one_hot.append([0., 1.])\n",
    "      \n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7IUMLV2IbkoA"
   },
   "outputs": [],
   "source": [
    "labels_one_hot = np.array(labels_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DD56O2LZ1rNU"
   },
   "source": [
    "### Pickling all the data\n",
    "\n",
    "The Training data and Labels are pickled for reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mzFPn7muQeLW"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "embeddings_file = \"embeddings-{}.pickle\".format(len(tweet_embeddings))\n",
    "labels_file = \"labels-{}.pickle\".format(len(labels))\n",
    "\n",
    "pickle.dump(tweet_embeddings, open(embeddings_file, 'wb'))\n",
    "pickle.dump(labels_one_hot, open(labels_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1173,
     "status": "ok",
     "timestamp": 1532882550420,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "fa2_AN6vbfkc",
    "outputId": "08945596-59a4-4acd-d1cd-18c3126a8dfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfbK-6o_7hO9"
   },
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Zq-g_QDmZC-n"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tweet_embeddings = pickle.load(open('tweets_embeddings.pickle', 'rb'))\n",
    "labels = pickle.load(open('labels-one_hot.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oy3kG1457dm4"
   },
   "source": [
    "### Dataset Partition\n",
    "\n",
    "Spliting the tweets and labels in `(x_train, y_train)` and `(x_test, y_test)` with 90% for training and 10% for testing from all the tweets.\n",
    "\n",
    "Maximum number of tokens allowed for each tweet is set to be 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6clvTznWZCyt"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "B-unUWw0UXXL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(tweet_embeddings, labels, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1532869523661,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "bQZn7MN1abro",
    "outputId": "efe80983-6d82-4731-b911-6223ac9fbd6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360000, 512, 1), (360000, 2), (40000, 512, 1), (40000, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KSCD5uJ_lABj"
   },
   "outputs": [],
   "source": [
    "vector_size = 512\n",
    "batch_size = 500\n",
    "no_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EmQDXL_i7k6f"
   },
   "source": [
    "### Retraining the model if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9826,
     "status": "ok",
     "timestamp": 1532869534818,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "Ow90WsQ1k3kR",
    "outputId": "9f8d9758-5caf-42f3-fedc-0654e6442315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "'''from keras.models import load_model\n",
    "\n",
    "model = load_model('universal-sentence-encoder-400k.model')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRCjoxUM7rks"
   },
   "source": [
    "### Building the Neural Model\n",
    "\n",
    "For training a combination of Convolution Neural Network and Bidirectional Long Short Term Memory Network is used (CNN-LSTM).\n",
    "\n",
    "Batch Size is 100.\n",
    "\n",
    "\n",
    "To prevent overfitting or over training of the network, `EarlyStopping()` is used in `callbacks` thus if the network does not improve or starts overfitting, the training comes to an end.\n",
    "\n",
    "**Acrhitecture of Network:**\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "Conv1D -> Conv1D -> Conv1D -> Max Pooling1D -> Bidirectional LSTM -> Dense -> Dropout -> Dense -> Dropout -> Dense -> Dropout -> Output\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "Total params: 3,289,794\n",
    "\n",
    "Trainable params: 3,289,794\n",
    "\n",
    "Non-trainable params: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6866,
     "status": "ok",
     "timestamp": 1532869556839,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "YIBB3pK6Z_au",
    "outputId": "d9900459-fab8-49cf-9050-782cf65e1885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 512, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 512, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 512, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 170, 32)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 1024)              2232320   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,289,794\n",
      "Trainable params: 3,289,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same',\n",
    "                 input_shape=(vector_size, 1)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "\n",
    "model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMDUPJRm7WeX"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12172179,
     "status": "ok",
     "timestamp": 1532881730967,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "XICT3ZbqaPL2",
    "outputId": "5207c92b-411e-4b41-a8aa-66c6da689396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "333500/360000 [==========================>...] - ETA: 1:26 - loss: 0.4902 - acc: 0.7604360000/360000 [==============================] - 1217s 3ms/step - loss: 0.4904 - acc: 0.7604 - val_loss: 0.4871 - val_acc: 0.7617\n",
      "Epoch 2/10\n",
      "207500/360000 [================>.............] - ETA: 8:17 - loss: 0.4892 - acc: 0.7607360000/360000 [==============================] - 1213s 3ms/step - loss: 0.4892 - acc: 0.7611 - val_loss: 0.4785 - val_acc: 0.7693\n",
      "Epoch 3/10\n",
      "159500/360000 [============>.................] - ETA: 10:52 - loss: 0.4864 - acc: 0.7631360000/360000 [==============================] - 1213s 3ms/step - loss: 0.4873 - acc: 0.7626 - val_loss: 0.4786 - val_acc: 0.7706\n",
      "Epoch 4/10\n",
      "141500/360000 [==========>...................] - ETA: 11:53 - loss: 0.4856 - acc: 0.7637360000/360000 [==============================] - 1217s 3ms/step - loss: 0.4860 - acc: 0.7628 - val_loss: 0.4780 - val_acc: 0.7684\n",
      "Epoch 5/10\n",
      "134500/360000 [==========>...................] - ETA: 12:19 - loss: 0.4865 - acc: 0.7633360000/360000 [==============================] - 1219s 3ms/step - loss: 0.4845 - acc: 0.7647 - val_loss: 0.4784 - val_acc: 0.7688\n",
      "Epoch 6/10\n",
      "131500/360000 [=========>....................] - ETA: 12:24 - loss: 0.4834 - acc: 0.7654360000/360000 [==============================] - 1216s 3ms/step - loss: 0.4833 - acc: 0.7645 - val_loss: 0.4753 - val_acc: 0.7706\n",
      "Epoch 7/10\n",
      "130500/360000 [=========>....................] - ETA: 12:29 - loss: 0.4826 - acc: 0.7669360000/360000 [==============================] - 1218s 3ms/step - loss: 0.4824 - acc: 0.7657 - val_loss: 0.4757 - val_acc: 0.7705\n",
      "Epoch 8/10\n",
      "130000/360000 [=========>....................] - ETA: 12:35 - loss: 0.4801 - acc: 0.7674360000/360000 [==============================] - 1220s 3ms/step - loss: 0.4810 - acc: 0.7664 - val_loss: 0.4748 - val_acc: 0.7712\n",
      "Epoch 9/10\n",
      "130000/360000 [=========>....................] - ETA: 12:31 - loss: 0.4809 - acc: 0.7666360000/360000 [==============================] - 1220s 3ms/step - loss: 0.4799 - acc: 0.7668 - val_loss: 0.4777 - val_acc: 0.7682\n",
      "Epoch 10/10\n",
      "129500/360000 [=========>....................] - ETA: 12:31 - loss: 0.4783 - acc: 0.7675360000/360000 [==============================] - 1217s 3ms/step - loss: 0.4788 - acc: 0.7674 - val_loss: 0.4820 - val_acc: 0.7678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f193166e9b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x_train), np.array(y_train), batch_size=batch_size, epochs=no_epochs,\n",
    "         validation_data=(np.array(x_test), np.array(y_test)), callbacks=[tensorboard, EarlyStopping(min_delta=0.0001, patience=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJlbjZ767H56"
   },
   "source": [
    "### Evaluating the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1532882663996,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "4DTKqaW-7O7K",
    "outputId": "ea4d8a3e-229c-4a01-e89a-077fd6a49cae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42046,
     "status": "ok",
     "timestamp": 1532881778761,
     "user": {
      "displayName": "MANDAV",
      "photoUrl": "//lh4.googleusercontent.com/-Zi5_ERBmNoM/AAAAAAAAAAI/AAAAAAAAASc/1pLc_S0nstI/s50-c-k-no/photo.jpg",
      "userId": "113535474679329766874"
     },
     "user_tz": -330
    },
    "id": "z6VBcx8Uk1Q0",
    "outputId": "4ffb2626-6a0d-4725-b41b-f9e7da3ca81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 41s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48201919458806514, 0.7677500016987324]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-Xy1vtY7Ec_"
   },
   "source": [
    "### Saving the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "11ivLha9kcb1"
   },
   "outputs": [],
   "source": [
    "model.save('universal-sentence-encoder-400k.model')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "universal-sentence-encoder-training.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
